{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## LSTM Pytorch implementation  \n","\n","* 본 실습의 목적은 LSTM model을 Pytorch를 사용하여 구현하고, 이를 활용하여 kaggle에 있는 dataset에 적용해보는 것입니다.\n","* 필요한 module은 conda나 pip을 사용하여 다운로드해주시면 되고, colab에서 진행하신다면 kaggle api를 다운로드하여 업로드해주시면 될 것 같습니다.  \n","* code의 출처는 아래 달아놓았습니다.  \n","* https://www.kaggle.com/code/bminixhofer/simple-lstm-pytorch-version"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["* 본 실습의 목적은 **toxic comment** 를 선별하는 model를 만들어내는 것입니다.  \n","* 이전의 model들은 문맥을 파악하지 않고 단어에 즉각적으로 반응하는 형태로 구현이 이루어졌습니다.  \n","(ex) \"I am a gay woman\" 을 toxic 문장으로 판별  \n","* **본 구현의 목적은 이러한 bias를 최소화시켜서 정확하게 toxic comment을 선별하는 모델을 구현하는 것입니다.**\n","* LSTM을 활용하여 구현한 code가 있어서 가져와보았으며, 중간중간에 주석으로 설명을 달아놓았습니다."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Preface"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This kernel is a PyTorch version of the [Simple LSTM kernel](https://www.kaggle.com/thousandvoices/simple-lstm). All credit for architecture and preprocessing goes to @thousandvoices.\n","There is a lot of discussion whether Keras, PyTorch, Tensorflow or the CUDA C API is best. But specifically between the PyTorch and Keras version of the simple LSTM architecture, there are 2 clear advantages of PyTorch:\n","- Speed. The PyTorch version runs about 20 minutes faster.\n","- Determinism. The PyTorch version is fully deterministic. Especially when it gets harder to improve your score later in the competition, determinism is very important.\n","\n","I was surprised to see that PyTorch is that much faster, so I'm not completely sure the steps taken are exactly the same. If you see any difference, we can discuss it in the comments :)\n","\n","The most likely reason the score of this kernel is higher than the @thousandvoices version is that the optimizer is not reinitialized after every epoch and thus the parameter-specific learning rates of Adam are not discarded after every epoch. That is the only difference between the kernels that is intended."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Imports & Utility functions"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-03T12:24:29.117623Z","iopub.status.busy":"2023-07-03T12:24:29.117315Z","iopub.status.idle":"2023-07-03T12:24:31.133705Z","shell.execute_reply":"2023-07-03T12:24:31.132959Z","shell.execute_reply.started":"2023-07-03T12:24:29.117563Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using TensorFlow backend.\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import time\n","import gc\n","import random\n","from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n","from keras.preprocessing import text, sequence\n","import torch\n","from torch import nn\n","from torch.utils import data\n","from torch.nn import functional as F"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T12:27:52.534146Z","iopub.status.busy":"2023-07-03T12:27:52.533837Z","iopub.status.idle":"2023-07-03T12:27:52.539054Z","shell.execute_reply":"2023-07-03T12:27:52.538255Z","shell.execute_reply.started":"2023-07-03T12:27:52.534089Z"},"trusted":true},"outputs":[],"source":["# disable progress bars when submitting\n","def is_interactive():\n","   return 'SHLVL' not in os.environ\n","\n","if not is_interactive():\n","    def nop(it, *a, **k):\n","        return it\n","\n","    tqdm = nop"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T12:28:11.116848Z","iopub.status.busy":"2023-07-03T12:28:11.116504Z","iopub.status.idle":"2023-07-03T12:28:11.125987Z","shell.execute_reply":"2023-07-03T12:28:11.124977Z","shell.execute_reply.started":"2023-07-03T12:28:11.116784Z"},"trusted":true},"outputs":[],"source":["# seed number is not that important, the point is that we are seeding so that the result will be same every time we run the program\n","def seed_everything(seed=1234):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","seed_everything()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T12:28:15.729377Z","iopub.status.busy":"2023-07-03T12:28:15.728932Z","iopub.status.idle":"2023-07-03T12:28:15.734816Z","shell.execute_reply":"2023-07-03T12:28:15.733950Z","shell.execute_reply.started":"2023-07-03T12:28:15.729310Z"},"trusted":true},"outputs":[],"source":["# 2 kinds of embeddings exist, following are the 2 paths for the pretrained model\n","CRAWL_EMBEDDING_PATH = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\n","GLOVE_EMBEDDING_PATH = '../input/glove840b300dtxt/glove.840B.300d.txt'\n","NUM_MODELS = 2\n","LSTM_UNITS = 128\n","DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n","MAX_LEN = 220"]},{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2023-07-03T12:28:16.906340Z","iopub.status.busy":"2023-07-03T12:28:16.906029Z","iopub.status.idle":"2023-07-03T12:28:16.913269Z","shell.execute_reply":"2023-07-03T12:28:16.912371Z","shell.execute_reply.started":"2023-07-03T12:28:16.906281Z"},"trusted":true},"outputs":[],"source":["# np.asarray is almost the same as np.array, but the difference is that it is a shallow copy(has the same reference)\n","def get_coefs(word, *arr):\n","    return word, np.asarray(arr, dtype='float32')\n","\n","def load_embeddings(path):\n","    with open(path) as f:\n","        return dict(get_coefs(*line.strip().split(' ')) for line in tqdm(f))\n","\n","def build_matrix(word_index, path):\n","    embedding_index = load_embeddings(path)\n","    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n","    unknown_words = []\n","    \n","    for word, i in word_index.items():\n","        try:\n","            embedding_matrix[i] = embedding_index[word]\n","        except KeyError:\n","            unknown_words.append(word)\n","    return embedding_matrix, unknown_words"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T12:28:19.685074Z","iopub.status.busy":"2023-07-03T12:28:19.684764Z","iopub.status.idle":"2023-07-03T12:28:19.698275Z","shell.execute_reply":"2023-07-03T12:28:19.697433Z","shell.execute_reply.started":"2023-07-03T12:28:19.685020Z"},"trusted":true},"outputs":[],"source":["#sigmoid for activation function\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def train_model(model, train, test, loss_fn, output_dim, lr=0.001,\n","                batch_size=512, n_epochs=4,\n","                enable_checkpoint_ensemble=True):\n","    param_lrs = [{'params': param, 'lr': lr} for param in model.parameters()]\n","    # use the Adam optimizer which is an optimizer which is a mixture of the momentum and the RMS prop\n","    optimizer = torch.optim.Adam(param_lrs, lr=lr)\n","\n","    # pytorch's LambdaLr function enables us to schedule the learning rate with the lambda function we make\n","    # make the learning rate decay as an exponential function\n","    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.6 ** epoch)\n","    \n","    # we usually shuffle the training dataset in order to create randomness\n","    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n","    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n","    all_test_preds = []\n","    checkpoint_weights = [2 ** epoch for epoch in range(n_epochs)]\n","    \n","    for epoch in range(n_epochs):\n","        start_time = time.time()\n","        \n","        scheduler.step()\n","        \n","        model.train()\n","        avg_loss = 0.\n","        \n","        for data in tqdm(train_loader, disable=False):\n","            x_batch = data[:-1]\n","            y_batch = data[-1]\n","\n","            y_pred = model(*x_batch)            \n","            loss = loss_fn(y_pred, y_batch)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","\n","            optimizer.step()\n","            avg_loss += loss.item() / len(train_loader)\n","            \n","        model.eval()\n","        test_preds = np.zeros((len(test), output_dim))\n","    \n","        for i, x_batch in enumerate(test_loader):\n","            y_pred = sigmoid(model(*x_batch).detach().cpu().numpy())\n","\n","            test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred\n","\n","        all_test_preds.append(test_preds)\n","        elapsed_time = time.time() - start_time\n","        print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n","              epoch + 1, n_epochs, avg_loss, elapsed_time))\n","\n","    if enable_checkpoint_ensemble:\n","        test_preds = np.average(all_test_preds, weights=checkpoint_weights, axis=0)    \n","    else:\n","        test_preds = all_test_preds[-1]\n","        \n","    return test_preds"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T12:28:21.313558Z","iopub.status.busy":"2023-07-03T12:28:21.313252Z","iopub.status.idle":"2023-07-03T12:28:21.326290Z","shell.execute_reply":"2023-07-03T12:28:21.325466Z","shell.execute_reply.started":"2023-07-03T12:28:21.313500Z"},"trusted":true},"outputs":[],"source":["class SpatialDropout(nn.Dropout2d):\n","    def forward(self, x):\n","        x = x.unsqueeze(2)    # (N, T, 1, K)\n","        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n","        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n","        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n","        x = x.squeeze(2)  # (N, T, K)\n","        return x\n","    \n","class NeuralNet(nn.Module):\n","    def __init__(self, embedding_matrix, num_aux_targets):\n","        super(NeuralNet, self).__init__()\n","        embed_size = embedding_matrix.shape[1]\n","        \n","        self.embedding = nn.Embedding(max_features, embed_size)\n","        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n","        self.embedding.weight.requires_grad = False\n","        self.embedding_dropout = SpatialDropout(0.3)\n","        \n","        self.lstm1 = nn.LSTM(embed_size, LSTM_UNITS, bidirectional=True, batch_first=True)\n","        self.lstm2 = nn.LSTM(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True)\n","    \n","        self.linear1 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n","        self.linear2 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n","        \n","        self.linear_out = nn.Linear(DENSE_HIDDEN_UNITS, 1)\n","        self.linear_aux_out = nn.Linear(DENSE_HIDDEN_UNITS, num_aux_targets)\n","        \n","    def forward(self, x):\n","        h_embedding = self.embedding(x)\n","        h_embedding = self.embedding_dropout(h_embedding)\n","        \n","        h_lstm1, _ = self.lstm1(h_embedding)\n","        h_lstm2, _ = self.lstm2(h_lstm1)\n","        \n","        # global average pooling\n","        avg_pool = torch.mean(h_lstm2, 1)\n","        # global max pooling\n","        max_pool, _ = torch.max(h_lstm2, 1)\n","        \n","        h_conc = torch.cat((max_pool, avg_pool), 1)\n","        h_conc_linear1  = F.relu(self.linear1(h_conc))\n","        h_conc_linear2  = F.relu(self.linear2(h_conc))\n","        \n","        hidden = h_conc + h_conc_linear1 + h_conc_linear2\n","        \n","        result = self.linear_out(hidden)\n","        aux_result = self.linear_aux_out(hidden)\n","        out = torch.cat([result, aux_result], 1)\n","        \n","        return out"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T12:28:23.050473Z","iopub.status.busy":"2023-07-03T12:28:23.050163Z","iopub.status.idle":"2023-07-03T12:28:23.057036Z","shell.execute_reply":"2023-07-03T12:28:23.054790Z","shell.execute_reply.started":"2023-07-03T12:28:23.050415Z"},"trusted":true},"outputs":[],"source":["def preprocess(data):\n","    '''\n","    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n","    '''\n","    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n","\n","    #parse the upper chars to blank space\n","    def clean_special_chars(text, punct):\n","        for p in punct:\n","            text = text.replace(p, ' ')\n","        return text\n","\n","    data = data.astype(str).apply(lambda x: clean_special_chars(x, punct))\n","    return data"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T12:28:25.125440Z","iopub.status.busy":"2023-07-03T12:28:25.125143Z","iopub.status.idle":"2023-07-03T12:29:22.614701Z","shell.execute_reply":"2023-07-03T12:29:22.613958Z","shell.execute_reply.started":"2023-07-03T12:28:25.125383Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n","test = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\n","\n","x_train = preprocess(train['comment_text'])\n","y_train = np.where(train['target'] >= 0.5, 1, 0)\n","y_aux_train = train[['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']]\n","x_test = preprocess(test['comment_text'])"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T14:34:40.031059Z","iopub.status.busy":"2023-07-03T14:34:40.030718Z","iopub.status.idle":"2023-07-03T14:34:40.134735Z","shell.execute_reply":"2023-07-03T14:34:40.133647Z","shell.execute_reply.started":"2023-07-03T14:34:40.031000Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>target</th>\n","      <th>comment_text</th>\n","      <th>severe_toxicity</th>\n","      <th>obscene</th>\n","      <th>identity_attack</th>\n","      <th>insult</th>\n","      <th>threat</th>\n","      <th>asian</th>\n","      <th>atheist</th>\n","      <th>bisexual</th>\n","      <th>black</th>\n","      <th>buddhist</th>\n","      <th>christian</th>\n","      <th>female</th>\n","      <th>heterosexual</th>\n","      <th>hindu</th>\n","      <th>homosexual_gay_or_lesbian</th>\n","      <th>intellectual_or_learning_disability</th>\n","      <th>jewish</th>\n","      <th>latino</th>\n","      <th>male</th>\n","      <th>muslim</th>\n","      <th>other_disability</th>\n","      <th>other_gender</th>\n","      <th>other_race_or_ethnicity</th>\n","      <th>other_religion</th>\n","      <th>other_sexual_orientation</th>\n","      <th>physical_disability</th>\n","      <th>psychiatric_or_mental_illness</th>\n","      <th>transgender</th>\n","      <th>white</th>\n","      <th>created_date</th>\n","      <th>publication_id</th>\n","      <th>parent_id</th>\n","      <th>article_id</th>\n","      <th>rating</th>\n","      <th>funny</th>\n","      <th>wow</th>\n","      <th>sad</th>\n","      <th>likes</th>\n","      <th>disagree</th>\n","      <th>sexual_explicit</th>\n","      <th>identity_annotator_count</th>\n","      <th>toxicity_annotator_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>59848</td>\n","      <td>0.000000</td>\n","      <td>This is so cool. It's like, 'would you want yo...</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2015-09-29 10:50:41.987077+00</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>2006</td>\n","      <td>rejected</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>59849</td>\n","      <td>0.000000</td>\n","      <td>Thank you!! This would make my life a lot less...</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2015-09-29 10:50:42.870083+00</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>2006</td>\n","      <td>rejected</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>59852</td>\n","      <td>0.000000</td>\n","      <td>This is such an urgent design problem; kudos t...</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2015-09-29 10:50:45.222647+00</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>2006</td>\n","      <td>rejected</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>59855</td>\n","      <td>0.000000</td>\n","      <td>Is this something I'll be able to install on m...</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2015-09-29 10:50:47.601894+00</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>2006</td>\n","      <td>rejected</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>59856</td>\n","      <td>0.893617</td>\n","      <td>haha you guys are a bunch of losers.</td>\n","      <td>0.021277</td>\n","      <td>0.0</td>\n","      <td>0.021277</td>\n","      <td>0.87234</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.25</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2015-09-29 10:50:48.488476+00</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>2006</td>\n","      <td>rejected</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>4</td>\n","      <td>47</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id            ...             toxicity_annotator_count\n","0  59848            ...                                    4\n","1  59849            ...                                    4\n","2  59852            ...                                    4\n","3  59855            ...                                    4\n","4  59856            ...                                   47\n","\n","[5 rows x 45 columns]"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["train.head()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T12:30:50.143209Z","iopub.status.busy":"2023-07-03T12:30:50.142894Z","iopub.status.idle":"2023-07-03T12:30:50.147222Z","shell.execute_reply":"2023-07-03T12:30:50.146340Z","shell.execute_reply.started":"2023-07-03T12:30:50.143154Z"},"trusted":true},"outputs":[],"source":["max_features = None"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T12:30:50.918940Z","iopub.status.busy":"2023-07-03T12:30:50.918393Z","iopub.status.idle":"2023-07-03T12:35:07.444824Z","shell.execute_reply":"2023-07-03T12:35:07.443845Z","shell.execute_reply.started":"2023-07-03T12:30:50.918644Z"},"trusted":true},"outputs":[],"source":["tokenizer = text.Tokenizer()\n","tokenizer.fit_on_texts(list(x_train) + list(x_test))\n","\n","x_train = tokenizer.texts_to_sequences(x_train)\n","x_test = tokenizer.texts_to_sequences(x_test)\n","x_train = sequence.pad_sequences(x_train, maxlen=MAX_LEN)\n","x_test = sequence.pad_sequences(x_test, maxlen=MAX_LEN)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T12:35:31.219192Z","iopub.status.busy":"2023-07-03T12:35:31.218873Z","iopub.status.idle":"2023-07-03T12:35:31.226794Z","shell.execute_reply":"2023-07-03T12:35:31.225946Z","shell.execute_reply.started":"2023-07-03T12:35:31.219130Z"},"trusted":true},"outputs":[{"data":{"text/plain":["327009"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["max_features = max_features or len(tokenizer.word_index) + 1\n","max_features"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T12:35:32.378332Z","iopub.status.busy":"2023-07-03T12:35:32.377791Z","iopub.status.idle":"2023-07-03T12:39:52.811855Z","shell.execute_reply":"2023-07-03T12:39:52.810993Z","shell.execute_reply.started":"2023-07-03T12:35:32.378284Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["n unknown words (crawl):  173678\n"]}],"source":["crawl_matrix, unknown_words_crawl = build_matrix(tokenizer.word_index, CRAWL_EMBEDDING_PATH)\n","print('n unknown words (crawl): ', len(unknown_words_crawl))"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T12:41:45.156857Z","iopub.status.busy":"2023-07-03T12:41:45.156519Z","iopub.status.idle":"2023-07-03T12:46:38.741358Z","shell.execute_reply":"2023-07-03T12:46:38.740486Z","shell.execute_reply.started":"2023-07-03T12:41:45.156799Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["n unknown words (glove):  170383\n"]}],"source":["glove_matrix, unknown_words_glove = build_matrix(tokenizer.word_index, GLOVE_EMBEDDING_PATH)\n","print('n unknown words (glove): ', len(unknown_words_glove))"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T12:56:26.007546Z","iopub.status.busy":"2023-07-03T12:56:26.007222Z","iopub.status.idle":"2023-07-03T12:56:26.707865Z","shell.execute_reply":"2023-07-03T12:56:26.706792Z","shell.execute_reply.started":"2023-07-03T12:56:26.007486Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["embedding_matrix = np.concatenate([crawl_matrix, glove_matrix], axis=-1)\n","embedding_matrix.shape\n","\n","del crawl_matrix\n","del glove_matrix\n","gc.collect()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T14:32:28.718217Z","iopub.status.busy":"2023-07-03T14:32:28.717907Z","iopub.status.idle":"2023-07-03T14:32:28.733913Z","shell.execute_reply":"2023-07-03T14:32:28.733006Z","shell.execute_reply.started":"2023-07-03T14:32:28.718162Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([ 2.30999999e-02,  1.70000009e-02,  1.56999994e-02, -7.72999972e-02,\n","        1.08800001e-01,  3.10000009e-03, -1.48699999e-01, -2.67199993e-01,\n","       -3.57000008e-02, -4.87000011e-02,  8.07000026e-02,  1.53200001e-01,\n","       -7.38999993e-02, -2.91000009e-02, -4.45000008e-02, -1.39999995e-03,\n","        1.01400003e-01,  1.86000001e-02, -2.52999999e-02,  1.99999996e-02,\n","       -2.60000001e-03, -1.78999994e-02,  5.00000024e-04,  5.40000014e-03,\n","       -1.33999996e-02,  2.32999995e-02, -7.54999965e-02, -1.55999996e-02,\n","        4.14999984e-02, -4.98499990e-01,  4.10000011e-02, -6.15999997e-02,\n","        4.69999993e-03,  3.24999988e-02, -1.62000004e-02, -1.72000006e-02,\n","        9.88000035e-02,  7.66000003e-02, -7.95999989e-02, -3.44999991e-02,\n","        1.24000004e-02, -1.00699998e-01, -2.92000007e-02, -7.62000009e-02,\n","       -1.26100004e-01, -5.31000011e-02,  4.23999988e-02,  1.43999998e-02,\n","       -6.83000013e-02,  2.85899997e-01,  3.99000011e-02,  2.00999994e-02,\n","        3.24000001e-01, -6.56000003e-02, -4.96999994e-02,  8.99999961e-03,\n","        9.01999995e-02, -1.37999998e-02, -4.12000008e-02, -2.96999998e-02,\n","        3.13899994e-01, -1.42800003e-01,  1.65999997e-02, -2.19000001e-02,\n","       -5.75000010e-02,  1.35900006e-01, -1.65500000e-01,  1.90000003e-03,\n","        3.22999991e-02, -1.30000000e-03, -3.03299993e-01, -9.10000037e-03,\n","        1.46200001e-01,  1.86000004e-01, -5.24000004e-02,  1.88600004e-01,\n","       -7.37200022e-01, -2.48000007e-02, -2.05000006e-02,  2.19999999e-03,\n","        5.98800004e-01, -3.59000005e-02, -2.69000009e-02, -4.83000018e-02,\n","        1.09000001e-02, -4.39999998e-03,  5.92000000e-02,  1.74000002e-02,\n","        1.00000005e-03, -1.20000006e-03, -2.51000002e-02,  4.62000012e-01,\n","       -4.43000011e-02, -3.50000001e-02,  1.15000000e-02,  1.49599999e-01,\n","        3.12500000e-01, -9.10000037e-03,  2.51700014e-01,  6.53999969e-02,\n","        2.37000007e-02, -4.32000011e-02,  9.52000022e-02,  6.49999976e-02,\n","       -2.93199986e-01,  6.30000010e-02,  2.36000009e-02,  3.40000018e-02,\n","       -1.20000006e-03,  8.88999999e-02, -6.00000028e-04, -1.73600003e-01,\n","        3.73999998e-02,  3.13000008e-02, -6.18399978e-01,  2.82000005e-02,\n","       -3.83599997e-01,  5.88999987e-02,  2.44299993e-01,  6.01999983e-02,\n","        5.70000010e-03, -3.80000006e-03,  1.35199994e-01,  5.29999984e-03,\n","        1.93000007e-02, -2.12999992e-02,  2.48000007e-02,  2.14000009e-02,\n","        2.33400002e-01, -4.38000001e-02,  5.27000017e-02,  2.62000002e-02,\n","        6.54999986e-02, -8.59000012e-02,  2.64200002e-01, -3.92999984e-02,\n","       -1.63000003e-02,  6.80999979e-02, -1.75000001e-02, -1.15800001e-01,\n","        9.49999988e-02,  4.74999994e-02,  6.89999992e-03,  5.16399980e-01,\n","       -2.60000001e-03, -2.54999995e-02, -8.00999999e-02, -2.62000002e-02,\n","        1.11299999e-01,  7.98000023e-02, -1.50000001e-03,  2.52000000e-02,\n","       -3.79000008e-02, -2.60000005e-02, -2.82000005e-02, -4.19999994e-02,\n","        4.82000001e-02, -1.75000001e-02,  2.82000005e-02,  3.99999991e-02,\n","        3.99800003e-01, -1.05400003e-01,  7.54999965e-02,  1.02700002e-01,\n","       -1.98999997e-02,  3.81000005e-02, -3.33000012e-02, -3.42000015e-02,\n","        2.66999993e-02,  8.64999965e-02,  2.40000011e-03, -9.10000037e-03,\n","        1.63000003e-02, -2.86999997e-02,  3.64000015e-02, -2.01999992e-02,\n","       -3.66999991e-02, -3.55999991e-02, -6.14000000e-02, -5.51000014e-02,\n","        2.64899999e-01, -3.70999984e-02,  2.07000002e-02,  3.64000015e-02,\n","        5.11999987e-02, -8.42999965e-02, -1.37999998e-02,  7.10000023e-02,\n","        8.42999965e-02,  2.91000009e-02, -9.99999978e-03,  3.97999994e-02,\n","       -6.45999983e-02, -5.95000014e-02, -2.58000009e-02, -2.82000005e-02,\n","        3.10999993e-02,  1.47000002e-02, -4.49000001e-02,  2.75999997e-02,\n","       -1.16800003e-01,  2.19000001e-02, -2.30999999e-02, -1.62000004e-02,\n","       -2.85999998e-02,  1.27999997e-02, -2.59000007e-02,  1.53000001e-02,\n","        1.04199998e-01, -1.20700002e-01, -1.35000004e-02,  5.40499985e-01,\n","       -3.62000018e-02,  4.76000011e-02, -1.79999992e-02, -7.34999999e-02,\n","        3.40000005e-03, -2.60000001e-03, -5.70000010e-03,  3.79999988e-02,\n","       -4.01000008e-02, -1.01599999e-01,  3.44000012e-02,  4.01999988e-02,\n","        5.13000004e-02, -8.15000013e-02,  3.90000008e-02,  7.60000013e-03,\n","        1.75000001e-02,  3.00000003e-03, -7.06999972e-02,  1.49999997e-02,\n","       -1.17399998e-01,  2.65999995e-02, -7.94999972e-02,  1.98799998e-01,\n","        9.78000015e-02, -5.86999990e-02, -5.33000007e-02,  2.73000002e-02,\n","        4.41999994e-02, -4.63000014e-02, -7.07999989e-02,  1.75999999e-02,\n","       -9.93999988e-02,  8.46000016e-02,  3.61999989e-01, -2.07000002e-02,\n","        2.55999994e-02, -1.44999996e-02,  3.08999997e-02,  8.20000004e-03,\n","        4.19999985e-03, -3.13999988e-02,  1.19599998e-01, -3.46000008e-02,\n","        3.86000015e-02, -3.68000008e-02, -3.33000012e-02, -3.19999992e-03,\n","       -4.80000023e-03, -6.00000028e-04,  5.09000011e-02, -2.31999997e-02,\n","        1.18299998e-01, -1.31400004e-01,  1.48999998e-02,  7.62000009e-02,\n","       -1.61000006e-02,  1.60000008e-02,  3.90000008e-02, -1.92200005e-01,\n","        3.10000009e-03, -6.66000023e-02,  5.93000017e-02, -6.21000007e-02,\n","        4.21000011e-02,  3.28000002e-02, -9.00999978e-02, -1.59000009e-02,\n","        1.01499997e-01,  6.16400003e-01, -6.49999976e-02,  1.24100000e-01,\n","        5.90000022e-03,  6.53000027e-02, -3.86000015e-02,  1.65999997e-02,\n","        4.03000005e-02,  1.68999992e-02, -7.99999980e-04,  5.20000001e-03,\n","       -3.62999998e-02, -2.50800014e-01,  1.25200003e-01, -1.00800000e-01,\n","       -3.07999998e-02,  7.44000003e-02, -1.11800000e-01,  9.62999985e-02,\n","        2.72040009e-01, -6.20299987e-02, -1.88400000e-01,  2.32250001e-02,\n","       -1.81580000e-02,  6.71919994e-03, -1.38769999e-01,  1.77080005e-01,\n","        1.77090004e-01,  2.58820009e+00, -3.51790011e-01, -1.73120007e-01,\n","        4.32850003e-01, -1.07079998e-01,  1.50059998e-01, -1.99819997e-01,\n","       -1.90929994e-01,  1.18710005e+00, -1.62070006e-01, -2.35379994e-01,\n","        3.66399996e-03, -1.91560000e-01, -8.56619999e-02,  3.91989984e-02,\n","       -6.64490014e-02, -4.20899987e-02, -1.91220000e-01,  1.16790002e-02,\n","       -3.71380001e-01,  2.18860000e-01,  1.14229997e-03,  4.31899995e-01,\n","       -1.42049998e-01,  3.80589992e-01,  3.06540012e-01,  2.01670006e-02,\n","       -1.83160007e-01, -6.51860004e-03, -8.05489998e-03, -1.20630004e-01,\n","        2.75069997e-02,  2.98390001e-01, -2.28960007e-01, -2.28819996e-01,\n","        1.46709993e-01, -7.63010010e-02, -1.26800001e-01, -6.66509988e-03,\n","       -5.27950004e-02,  1.42580003e-01,  1.56100005e-01,  5.55099994e-02,\n","       -1.61489993e-01,  9.62899998e-02, -7.65329972e-02, -4.99709994e-02,\n","       -1.01950001e-02, -4.76410016e-02, -1.66789994e-01, -2.39399999e-01,\n","        5.01410011e-03, -4.91750017e-02,  1.33379996e-02,  4.19230014e-01,\n","       -1.01039998e-01,  1.51110003e-02, -7.77060017e-02, -1.34709999e-01,\n","        1.19000003e-01,  1.08020000e-01,  2.10610002e-01, -5.19040003e-02,\n","        1.85269997e-01,  1.78560004e-01,  4.12929989e-02, -1.43849999e-02,\n","       -8.25669989e-02, -3.54829989e-02, -7.61730000e-02, -4.53669988e-02,\n","        8.92810002e-02,  3.36719990e-01, -2.20990002e-01, -6.72749989e-03,\n","        2.39830002e-01, -2.31470004e-01, -8.85919988e-01,  9.12970006e-02,\n","       -1.21229999e-02,  1.32330004e-02, -2.57990003e-01, -2.97200009e-02,\n","        1.67539995e-02,  1.36900004e-02,  3.23769987e-01,  3.95460017e-02,\n","        4.21140008e-02, -8.82430002e-02,  3.03180009e-01,  8.77470002e-02,\n","        1.63460001e-01, -4.04850006e-01, -4.38450016e-02, -4.06970009e-02,\n","        2.09360003e-01, -7.77949989e-01,  2.99699992e-01,  2.33400002e-01,\n","        1.48910001e-01, -3.90370011e-01, -5.30860014e-02,  6.29220009e-02,\n","        6.56630024e-02, -1.39060006e-01,  9.41929966e-02,  1.03440002e-01,\n","       -2.79700011e-01,  2.89050013e-01, -3.21610004e-01,  2.06870008e-02,\n","        6.32539988e-02, -2.32570007e-01, -4.35200006e-01, -1.70489997e-02,\n","       -3.27439994e-01, -4.70639989e-02, -7.51489997e-02, -1.87879995e-01,\n","       -1.50170000e-02,  2.93419994e-02, -3.52699995e-01, -4.42779996e-02,\n","       -1.35069996e-01, -1.16439998e-01, -1.04300000e-01,  1.39200002e-01,\n","        3.91989993e-03,  3.76029998e-01,  6.72169998e-02, -3.79920006e-01,\n","       -1.12409997e+00, -5.73569983e-02, -1.68259993e-01,  3.94099988e-02,\n","        2.60399997e-01, -2.38659997e-02,  1.79629996e-01,  1.35529995e-01,\n","        2.13900000e-01,  5.26329987e-02, -2.50330001e-01, -1.13070004e-01,\n","        2.22340003e-01,  6.65969998e-02, -1.11610003e-01,  6.24380000e-02,\n","       -2.79720008e-01,  1.98780000e-01, -3.62619996e-01, -1.00059997e-05,\n","       -1.72619998e-01,  2.91660011e-01, -1.57230005e-01,  5.42949997e-02,\n","        6.10099994e-02, -3.91649991e-01,  2.76600003e-01,  5.78159988e-02,\n","        3.97089988e-01,  2.52289996e-02,  2.46720001e-01, -8.90500024e-02,\n","        1.56829998e-01, -2.09600002e-01, -2.21959993e-01,  5.23939990e-02,\n","       -1.13599999e-02,  5.04169986e-02, -1.40230000e-01, -4.28249985e-02,\n","       -3.19310017e-02, -2.13359997e-01, -2.04019994e-01, -2.32720003e-01,\n","        7.44900033e-02,  8.82019997e-02, -1.10629998e-01, -3.35260004e-01,\n","       -1.40279997e-02, -2.94290006e-01, -8.69110003e-02, -1.32100001e-01,\n","       -4.36159998e-01,  2.05129996e-01,  7.93620013e-03,  4.85049993e-01,\n","        6.42369986e-02,  1.42609999e-01, -4.37110007e-01,  1.27829999e-01,\n","       -1.31109998e-01,  2.46730000e-01, -2.74960011e-01,  1.58960000e-01,\n","        4.33140010e-01,  9.02860016e-02,  2.46619999e-01,  6.64630011e-02,\n","       -2.00990006e-01,  1.10100001e-01,  3.64399999e-02,  1.73590004e-01,\n","       -1.56890005e-01, -8.63279998e-02, -1.73160002e-01,  3.69749993e-01,\n","       -4.03169990e-01, -6.48140013e-02, -3.41660008e-02, -1.37729999e-02,\n","        6.28539994e-02, -1.71829998e-01, -1.23659998e-01, -3.46629992e-02,\n","       -2.27929994e-01, -2.31720001e-01,  2.38999993e-01,  2.74729997e-01,\n","        1.53320000e-01,  1.06610000e-01, -6.09820001e-02, -2.48050001e-02,\n","       -1.34780005e-01,  1.79319993e-01, -3.73739988e-01, -2.89299991e-02,\n","       -1.11419998e-01, -8.38899985e-02, -5.59320003e-02,  6.80390000e-02,\n","       -1.07830003e-01,  1.46500006e-01,  9.46170017e-02, -8.45540017e-02,\n","        6.74289986e-02, -3.29100013e-01,  3.40819992e-02, -1.67469993e-01,\n","       -2.59970009e-01, -2.29169995e-01,  2.01590005e-02, -2.75800005e-02,\n","        1.61359996e-01, -1.85379997e-01,  3.76649983e-02,  5.76030016e-01,\n","        2.06839994e-01,  2.79410005e-01,  1.64770007e-01, -1.87689997e-02,\n","        1.20619997e-01,  6.96479976e-02,  5.90219982e-02, -2.31539994e-01,\n","        2.40950003e-01, -3.47099990e-01,  4.85399999e-02, -5.65019995e-02,\n","        4.15659994e-01, -4.31939989e-01,  4.82300013e-01, -5.17590009e-02,\n","       -2.72850007e-01, -2.58929998e-01,  1.65549994e-01, -1.83100000e-01,\n","       -6.73400015e-02,  4.24569994e-01,  1.03460001e-02,  1.42370000e-01,\n","        2.59389997e-01,  1.71230003e-01, -1.38209999e-01, -6.68459982e-02,\n","        1.59809999e-02, -3.01930010e-01,  4.35790010e-02, -4.31019999e-02,\n","        3.50250006e-01, -1.96810007e-01, -4.28099990e-01,  1.68990001e-01,\n","        2.25109994e-01, -2.85569996e-01, -1.02799997e-01, -1.81680005e-02,\n","        1.14069998e-01,  1.30150005e-01, -1.83170006e-01,  1.32300004e-01])"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# embedding result looks like this(Example)\n","embedding_matrix[1]"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T12:58:14.883537Z","iopub.status.busy":"2023-07-03T12:58:14.883195Z","iopub.status.idle":"2023-07-03T12:58:19.013504Z","shell.execute_reply":"2023-07-03T12:58:19.012528Z","shell.execute_reply.started":"2023-07-03T12:58:14.883475Z"},"trusted":true},"outputs":[],"source":["x_train_torch = torch.tensor(x_train, dtype=torch.long).cuda()\n","x_test_torch = torch.tensor(x_test, dtype=torch.long).cuda()\n","y_train_torch = torch.tensor(np.hstack([y_train[:, np.newaxis], y_aux_train]), dtype=torch.float32).cuda()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T12:58:22.584663Z","iopub.status.busy":"2023-07-03T12:58:22.584362Z","iopub.status.idle":"2023-07-03T14:17:58.421536Z","shell.execute_reply":"2023-07-03T14:17:58.420490Z","shell.execute_reply.started":"2023-07-03T12:58:22.584604Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model  0\n","Epoch 1/4 \t loss=0.1094 \t time=597.14s\n","Epoch 2/4 \t loss=0.1034 \t time=595.75s\n","Epoch 3/4 \t loss=0.1019 \t time=594.84s\n","Epoch 4/4 \t loss=0.1010 \t time=595.79s\n","\n","Model  1\n","Epoch 1/4 \t loss=0.1096 \t time=597.44s\n","Epoch 2/4 \t loss=0.1035 \t time=596.50s\n","Epoch 3/4 \t loss=0.1020 \t time=594.67s\n","Epoch 4/4 \t loss=0.1011 \t time=595.85s\n","\n"]}],"source":["train_dataset = data.TensorDataset(x_train_torch, y_train_torch)\n","test_dataset = data.TensorDataset(x_test_torch)\n","\n","all_test_preds = []\n","\n","for model_idx in range(NUM_MODELS):\n","    print('Model ', model_idx)\n","    seed_everything(1234 + model_idx)\n","    \n","    model = NeuralNet(embedding_matrix, y_aux_train.shape[-1])\n","    model.cuda()\n","    \n","    test_preds = train_model(model, train_dataset, test_dataset, output_dim=y_train_torch.shape[-1], \n","                             loss_fn=nn.BCEWithLogitsLoss(reduction='mean'))\n","    all_test_preds.append(test_preds)\n","    print()"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-07-03T14:26:02.634424Z","iopub.status.busy":"2023-07-03T14:26:02.634091Z","iopub.status.idle":"2023-07-03T14:26:03.399895Z","shell.execute_reply":"2023-07-03T14:26:03.399054Z","shell.execute_reply.started":"2023-07-03T14:26:02.634367Z"},"trusted":true},"outputs":[],"source":["submission = pd.DataFrame.from_dict({\n","    'id': test['id'],\n","    'prediction': np.mean(all_test_preds, axis=0)[:, 0]\n","})\n","\n","submission.to_csv('submission.csv', index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"trusted":true},"source":["Note that the solution is not validated in this kernel. So for tuning anything, you should build a validation framework using e. g. KFold CV. If you just check what works best by submitting, you are very likely to overfit to the public LB."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Ways to improve this kernel"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This kernel is just a simple baseline kernel, so there are many ways to improve it. Some ideas to get you started:\n","- Add a contraction mapping. E. g. mapping \"is'nt\" to \"is not\" can help the network because \"not\" is explicitly mentioned. They were very popular in the recent quora competition, see for example [this kernel](https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing).\n","- Try to reduce the number of words that are not found in the embeddings. At the moment, around 170k words are not found. We can take some steps to decrease this amount, for example trying to find a vector for a processed (capitalized, stemmed, ...) version of the word when the vector for the regular word can not be found. See the [3rd place solution](https://www.kaggle.com/wowfattie/3rd-place) of the quora competition for an excellent implementation of this.\n","- Try cyclic learning rate (CLR). I have found CLR to almost always improve my network recently compared to the default parameters for Adam. In this case, we are already using a learning rate scheduler, so this might not be the case. But it is still worth to try it out. See for example my [my other PyTorch kernel](https://www.kaggle.com/bminixhofer/deterministic-neural-networks-using-pytorch) for an implementation of CLR in PyTorch.\n","- Use sequence bucketing to train faster and fit more networks into the two hours. The winning team of the quora competition successfully used sequence bucketing to drastically reduce the time it took to train RNNs. An excerpt from their [solution summary](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/80568#latest-487092):\n","\n","> We aimed at combining as many models as possible. To do this, we needed to improve runtime and the most important thing to achieve this was the following. We do not pad sequences to the same length based on the whole data, but just on a batch level. That means we conduct padding and truncation on the data generator level for each batch separately, so that length of the sentences in a batch can vary in size. Additionally, we further improved this by not truncating based on the length of the longest sequence in the batch, but based on the 95% percentile of lengths within the sequence. This improved runtime heavily and kept accuracy quite robust on single model level, and improved it by being able to average more models.\n","\n","- Try a (weighted) average of embeddings instead of concatenating them. A 600d vector for each word is a lot, it might work better to average them instead. See [this paper](https://www.aclweb.org/anthology/N18-2031) for why this even works.\n","- Limit the maximum number of words used to train the NN. At the moment, there is no limit set to the maximum number of words in the tokenizer, so we use every word that occurs in the training data, even if it is only mentioned once. This could lead to overfitting so it might be better to limit the maximum number of words to e. g. 100k.\n","\n","Thanks for reading. Good luck and have fun in this competition!"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}
